{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Implementation of Binary addition\n",
    "\n",
    "## Contents\n",
    "1. Generate sample data\n",
    "2. Build Tensorflow RNN model\n",
    "3. Train model\n",
    "4. Calculator wrapper\n",
    "\n",
    "Can be configured in 32, 16, and 8-bit modes however since the binary addition operation generalizes perfectly for each time step the bitwidth doesn't make much difference. For the same reason very few training examples are required to train the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "from IPython import display\n",
    "\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "# Max unsigned integer values\n",
    "max_uint32 = 2 ** 32 - 1\n",
    "max_uint16 = 2 ** 16 - 1\n",
    "max_uint8 = 2 ** 8 - 1\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "# Adder datatype\n",
    "# supports\n",
    "# uint32, uint16 and uint8\n",
    "dtype = \"uint32\"\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 3e-3\n",
    "hidden_neurons = 16\n",
    "\n",
    "# Training data\n",
    "samples = 256\n",
    "train_test_batches_split = 0.5\n",
    "batch_size = 16\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SampleData(object):\n",
    "\n",
    "    def __init__(self, samples, dtype, batch_size, train_test_batches_split):\n",
    "        valid_dtypes = {\"uint8\", \"uint16\", \"uint32\"}\n",
    "        if not dtype in valid_dtypes: raise ValueError(\"input dtype not in valid dtypes\")\n",
    "        if (samples % batch_size != 0): raise ValueError(\"samples must be multiple of batch_size\")\n",
    "        \n",
    "        self.dtype = dtype\n",
    "        \n",
    "        if dtype == \"uint8\":\n",
    "            self.bitwidth = 8\n",
    "        if dtype == \"uint16\":\n",
    "            self.bitwidth = 16\n",
    "        if dtype == \"uint32\":\n",
    "            self.bitwidth = 32\n",
    "        \n",
    "        self.x0_uint, self.x1_uint = self.gen_x(samples, dtype)\n",
    "        self.y_uint = self.calc_y(self.x0_uint, self.x1_uint, dtype)\n",
    "        \n",
    "        self.x0_bits = arr2inbits(self.x0_uint)\n",
    "        self.x1_bits = arr2inbits(self.x1_uint)\n",
    "        self.y_bits = arr2inbits(self.y_uint)\n",
    "        self.x0_samples_bits = np.reshape(self.x0_bits, [samples, self.bitwidth])\n",
    "        self.x1_samples_bits = np.reshape(self.x1_bits, [samples, self.bitwidth])\n",
    "        self.x_samples_bits_dims = np.dstack([self.x0_samples_bits, self.x1_samples_bits])\n",
    "        self.y_samples_bits_dims = np.reshape(self.y_bits, [samples, self.bitwidth, 1])\n",
    "        self.batch_count = int(samples / batch_size)\n",
    "        self.x_all = np.split(self.x_samples_bits_dims, self.batch_count, axis=0)\n",
    "        self.y_all = np.split(self.y_samples_bits_dims, self.batch_count, axis=0)\n",
    "        train_batches = int(train_test_batches_split * self.batch_count)\n",
    "        test_batches = self.batch_count - train_batches\n",
    "        self.x_train = self.x_all[:train_batches - 1]\n",
    "        self.y_train = self.y_all[:train_batches - 1]\n",
    "        self.x_test = self.x_all[train_batches:]\n",
    "        self.y_test = self.y_all[train_batches:]\n",
    "        logging.info(\"Training set size\")\n",
    "        print(\"Training set size:\")\n",
    "        self.print_batch_dims(name=\"x_train\", var=self.x_train)\n",
    "        self.print_batch_dims(name=\"y_train\", var=self.y_train)\n",
    "        print(\"Test set size:\")\n",
    "        self.print_batch_dims(name=\"x_test\", var=self.x_test)\n",
    "        self.print_batch_dims(name=\"y_test\", var=self.y_test)\n",
    "        \n",
    "    def gen_x(self, samples, dtype):\n",
    "        # Would be nice to generate x without replacement however it is too expensive at 32-bit.\n",
    "        x_init_uint8 = lambda : np.reshape(np.random.choice(max_uint8, samples,\n",
    "                                                 replace=True).astype(np.uint8), [samples, 1])\n",
    "        x_init_uint16 = lambda : np.reshape(np.random.choice(max_uint16, samples,\n",
    "                                                 replace=True).astype(np.uint16), [samples, 1])\n",
    "        x_init_uint32 = lambda : np.reshape(np.random.choice(max_uint32, samples,\n",
    "                                                 replace=True).astype(np.uint32), [samples, 1])\n",
    "        if dtype == \"uint8\":\n",
    "            x0_uint = x_init_uint8()\n",
    "            x1_uint = x_init_uint8()\n",
    "            temp_x = np.hstack([x0_uint, x1_uint])\n",
    "        if dtype == \"uint16\":\n",
    "            x0_uint = x_init_uint16()\n",
    "            x1_uint = x_init_uint16()\n",
    "            temp_x = np.hstack([x0_uint, x1_uint])\n",
    "        if dtype == \"uint32\":\n",
    "            x0_uint = x_init_uint32()\n",
    "            x1_uint = x_init_uint32()\n",
    "            temp_x = np.hstack([x0_uint, x1_uint])\n",
    "        return (x0_uint, x1_uint)\n",
    "        \n",
    "    def calc_y(self, x0_uint, x1_uint, dtype):\n",
    "        temp_x = np.hstack([x0_uint, x1_uint])\n",
    "        if dtype == \"uint8\":\n",
    "            y_uint = np.sum(temp_x, axis=1, dtype=np.uint8)\n",
    "        if dtype == \"uint16\":\n",
    "            y_uint = np.sum(temp_x, axis=1, dtype=np.uint16)\n",
    "        if dtype == \"uint32\":\n",
    "            y_uint = np.sum(temp_x, axis=1, dtype=np.uint32)\n",
    "        return y_uint\n",
    "        \n",
    "    def print_batch_dims(self, name, var):\n",
    "        print(name + \" batches : \" + str(len(var)))\n",
    "        print(name + \" batch shape: \" + str(var[0].shape))\n",
    "        \n",
    "        \n",
    "    def print_batch(self, batch_no):\n",
    "        print(self.x[batch_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr2inbits(x):\n",
    "    '''\n",
    "    Function for converting Unsigned bitwidth-bit integers to big endian binary representation.\n",
    "    Output is flipped so order is lsb to msb\n",
    "    '''\n",
    "    x_little_end = x.astype(x.dtype.newbyteorder(\"B\"))\n",
    "    x_little_end_uint8 = x_little_end.view(np.uint8)\n",
    "    x_bits = np.unpackbits(x_little_end_uint8)\n",
    "    x_bits_flipped = x_bits[::-1]\n",
    "    return x_bits_flipped\n",
    "def test_arr2inbits():\n",
    "    x_test = np.array([3,5], dtype=\"uint32\")\n",
    "    x_test_bits = arr2inbits(x_test)\n",
    "    assert (x_test_bits == np.array([1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0\n",
    "                                    ,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])).all()\n",
    "    x_test = np.array([3,5], dtype=\"uint8\")\n",
    "    x_test_bits = arr2inbits(x_test)\n",
    "    assert (x_test_bits == np.array([1,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0])).all()\n",
    "test_arr2inbits()\n",
    "def bits2arr(x, dtype):\n",
    "    x_bits_flipped = x[::-1]\n",
    "    x_int = np.packbits(x_bits_flipped)\n",
    "    if dtype == \"uint8\":\n",
    "        return x_int\n",
    "    if dtype == \"uint16\":\n",
    "        x_grouped_bytes = np.reshape(x_int, [int(x_int.shape[0] / 2), 2])\n",
    "        multiplier = np.array([2 ** 8, 1])\n",
    "    if dtype == \"uint32\":\n",
    "        x_grouped_bytes = np.reshape(x_int, [int(x_int.shape[0] / 4), 4])\n",
    "        multiplier = np.array([2 ** 24, 2 ** 16, 2 ** 8, 1])\n",
    "    x_weighted_grouped_bytes = multiplier * x_grouped_bytes\n",
    "    x_int_reduced = np.add.reduce(x_weighted_grouped_bytes, axis=1)\n",
    "    return x_int_reduced\n",
    "        \n",
    "def test_bits2arr():\n",
    "    x_test = np.array([1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0\n",
    "                                    ,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "    x_test_int = bits2arr(x_test, \"uint32\")\n",
    "    assert(x_test_int == np.array([3,5])).all()\n",
    "    x_test = np.array([0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "    x_test_int = bits2arr(x_test, \"uint32\")\n",
    "    assert(x_test_int == np.array([256])).all()\n",
    "test_bits2arr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:\n",
      "x_train batches : 7\n",
      "x_train batch shape: (16, 32, 2)\n",
      "y_train batches : 7\n",
      "y_train batch shape: (16, 32, 1)\n",
      "Test set size:\n",
      "x_test batches : 8\n",
      "x_test batch shape: (16, 32, 2)\n",
      "y_test batches : 8\n",
      "y_test batch shape: (16, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = SampleData(samples=samples, \n",
    "                        dtype=dtype, \n",
    "                        batch_size=batch_size, \n",
    "                        train_test_batches_split=train_test_batches_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Tensorflow RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RnnCell(object):\n",
    "    def __init__(self, hidden_neurons=16, bitwidth=32):\n",
    "        # Tensorflow placeholders\n",
    "        self.x = tf.placeholder(tf.float32, [None, bitwidth, 2], name=\"x\")\n",
    "        self.y = tf.placeholder(tf.float32 , [None, bitwidth, 1], name=\"y\")\n",
    "        self.initial_state = tf.placeholder(tf.float32 , [None, hidden_neurons], name=\"initial_state\")\n",
    "        \n",
    "        # Tensorflow weights and biases\n",
    "        self._weights, self._bias = {}, {}\n",
    "        \n",
    "        # Input layer parameters\n",
    "        self._weights[\"i_h\"] = tf.Variable(\n",
    "            tf.random_uniform([2, hidden_neurons], -0.1, 0.1), dtype=tf.float32, name=\"w_i_h\")\n",
    "\n",
    "        # Hidden layer parameters \n",
    "        self._weights[\"h_h\"] = tf.Variable(\n",
    "            tf.random_uniform([hidden_neurons, hidden_neurons], -0.1, 0.1), dtype=tf.float32, name=\"w_h_h\")\n",
    "        self._bias[\"h\"] = tf.Variable(\n",
    "            tf.random_uniform([hidden_neurons], -0.1, 0.1), dtype=tf.float32, name=\"b_h\")\n",
    "\n",
    "        # Output layer parameters\n",
    "        self._weights[\"h_o\"] = tf.Variable(tf.random_uniform([hidden_neurons, 1], -0.1, 0.1),dtype=tf.float32, name=\"w_h_o\")\n",
    "        self._bias[\"o\"] = tf.Variable(tf.random_uniform([1], -0.1, 0.1), dtype=tf.float32, name=\"b_o\")\n",
    "        # Extract time series as list \n",
    "        self._x_series = tf.unstack(self.x, axis=1)\n",
    "        self._y_series = tf.unstack(self.y, axis=1)\n",
    "        \n",
    "        h_0 = tf.Variable(np.zeros([1, hidden_neurons]),dtype=tf.float32)\n",
    "        h_0 = self.initial_state\n",
    "        self._h, self._logits_series = [], []\n",
    "        for current_input in self._x_series: \n",
    "            # Hidden layer activation is a function of current_inputs, previous hidden layer and bias. \n",
    "            temp_h_1 = tf.add(tf.matmul(current_input, self._weights[\"i_h\"]), self._bias[\"h\"])\n",
    "            h_1 = tf.nn.relu(tf.add(temp_h_1, tf.matmul(h_0, self._weights[\"h_h\"])))\n",
    "            # Output layer activation is a function of current hidden layer and bias\n",
    "            o_1_logit = tf.add(tf.matmul(h_1, self._weights[\"h_o\"]), self._bias[\"o\"])\n",
    "            # Previous hidden layer activation becomes the current hidden layer activation for\n",
    "            # the next timestep\n",
    "            self._logits_series.append(o_1_logit)\n",
    "            self._h.append(h_1)\n",
    "            h_0 = h_1\n",
    "        self.predictions_series = [tf.sigmoid(logits) for logits in self._logits_series]\n",
    "        predictions_labels = zip(self.predictions_series, self._y_series)\n",
    "        logits_labels = zip(self._logits_series, self._y_series)\n",
    "        self._losses = self.cost_func_logits(logits_labels)\n",
    "        self.total_loss = tf.reduce_mean(self._losses)\n",
    "        self.train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(self.total_loss)\n",
    "    \n",
    "    def cost_func_logits(self, logits_labels):\n",
    "        losses = []\n",
    "        for logits, labels in logits_labels:\n",
    "            losses.append(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rnn = RnnCell(hidden_neurons=hidden_neurons, bitwidth=train_data.bitwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(sess, rnn, x, y, initial_state):\n",
    "    total_loss_batch = []\n",
    "    predictions_batch = []\n",
    "    _y_series_batch = []\n",
    "    for batch_no in range(len(x)):\n",
    "        predictions, _y_series, total_loss, _ = sess.run(\n",
    "                        [rnn.predictions_series, \n",
    "                         rnn._y_series, \n",
    "                         rnn.total_loss, \n",
    "                         rnn.train_step],\n",
    "                        feed_dict={\n",
    "                            rnn.x: x[batch_no],\n",
    "                            rnn.y: y[batch_no],\n",
    "                            rnn.initial_state: initial_state\n",
    "                        })\n",
    "        total_loss_batch.append(total_loss)\n",
    "        predictions_batch += predictions\n",
    "        _y_series_batch += _y_series\n",
    "    return zip(predictions_batch, _y_series_batch, total_loss_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_epoch(sess, rnn, x, y, initial_state):\n",
    "    total_loss_batch = []\n",
    "    predictions_batch = []\n",
    "    _y_series_batch = []\n",
    "    for batch_no in range(len(x)):\n",
    "        predictions, _y_series, total_loss = sess.run(\n",
    "                        [rnn.predictions_series, \n",
    "                         rnn._y_series, \n",
    "                         rnn.total_loss],\n",
    "                        feed_dict={\n",
    "                            rnn.x: x[batch_no],\n",
    "                            rnn.y: y[batch_no],\n",
    "                            rnn.initial_state: initial_state\n",
    "                        })\n",
    "        total_loss_batch.append(total_loss)\n",
    "        predictions_batch += predictions\n",
    "        _y_series_batch += _y_series\n",
    "    return zip(predictions_batch, _y_series_batch, total_loss_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118c71668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_total_loss_series_all = []\n",
    "test_total_loss_series_all = []\n",
    "predictions_series_all = []\n",
    "_y_series_series_all = []\n",
    "init_state = np.zeros([batch_size, hidden_neurons])\n",
    "for epoch in range(epochs):\n",
    "    predictions_batch, _y_series_batch, train_total_loss_batch  = zip(*train_epoch(sess=sess, \n",
    "                                                                            rnn=my_rnn, \n",
    "                                                                            x=train_data.x_train, \n",
    "                                                                            y=train_data.y_train,\n",
    "                                                                            initial_state=init_state))\n",
    "    predictions_batch, _y_series_batch, test_total_loss_batch  = zip(*predict_epoch(sess=sess, \n",
    "                                                                            rnn=my_rnn, \n",
    "                                                                            x=train_data.x_test, \n",
    "                                                                            y=train_data.y_test,\n",
    "                                                                            initial_state=init_state))\n",
    "    train_total_loss_series_all.append(np.mean(train_total_loss_batch))\n",
    "    test_total_loss_series_all.append(np.mean(test_total_loss_batch))\n",
    "    plt.plot(range(len(train_total_loss_series_all)), train_total_loss_series_all, \"red\",\n",
    "             range(len(test_total_loss_series_all)), test_total_loss_series_all, \"blue\")\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculator Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNCalc(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, dtype, rnn):\n",
    "        self.rnn = rnn\n",
    "        if dtype==\"uint8\":\n",
    "            self.max_val = 2 ** 8 - 1\n",
    "            self.dtype = dtype\n",
    "            self.np_dtype = np.uint8\n",
    "        if dtype==\"uint16\":\n",
    "            self.dtype = dtype\n",
    "            self.max_val = 2 ** 16 -1\n",
    "            self.np_dtype = np.uint16\n",
    "        if dtype==\"uint32\":\n",
    "            self.dtype = dtype\n",
    "            self.max_val = 2 ** 32 -1\n",
    "            self.np_dtype = np.uint32\n",
    "        \n",
    "    def _check_input(self, input_str: str):\n",
    "        x_unsafe = input(input_str)\n",
    "        try:\n",
    "            int(x_unsafe)\n",
    "        except:\n",
    "            print(\"Not an integer!\")\n",
    "            return\n",
    "        if int(x_unsafe) < 0: \n",
    "            print(\"Input must not be less than 0\")\n",
    "            return\n",
    "        if int(x_unsafe) > self.max_val: \n",
    "            print(\"Input must not be greater than {}\".format(self.max_val))\n",
    "            return\n",
    "        x_safe = int(x_unsafe)\n",
    "        return x_safe\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            x0 = self._check_input(\"Please input x0 in range 0 to {}\".format(self.max_val))\n",
    "            x1 = self._check_input(\"Please input x1 in range 0 to {}\".format(self.max_val))\n",
    "            if x0 is not None and x1 is not None:\n",
    "                x0_bits = arr2inbits(np.array((x0,), dtype=self.np_dtype))\n",
    "                x1_bits = arr2inbits(np.array((x1,), dtype=self.np_dtype))\n",
    "                x = np.dstack([x0_bits, x1_bits])\n",
    "                print(\"x0 int val: {}\".format(x0))\n",
    "                print(\"x0 bin val: {}\".format(x0_bits))\n",
    "                print(\"x0 int val: {}\".format(x1))\n",
    "                print(\"x0 bin val: {}\".format(x1_bits))\n",
    "                predictions= sess.run(\n",
    "                [self.rnn.predictions_series],\n",
    "                feed_dict={\n",
    "                    self.rnn.x: x,\n",
    "                    self.rnn.initial_state: np.zeros([1, hidden_neurons])\n",
    "                })\n",
    "                rounded_predictions = np.around(predictions)\n",
    "                predictions_cleaned = np.reshape(np.array(rounded_predictions[0]), [32]).astype(self.np_dtype)\n",
    "                print(\"y  int val: {} and correct answer is {}\"\n",
    "                      .format(bits2arr(predictions_cleaned, self.dtype)[0], x0 + x1))\n",
    "                print(\"y  bin val: {}\".format(predictions_cleaned))\n",
    "                #DO CALCULATION\n",
    "            user_input = input(\"Do you wish to perform a new calculation? (y/N)\")\n",
    "            if user_input not in \"Yy\" :\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input x0 in range 0 to 4294967295343634\n",
      "Please input x1 in range 0 to 42949672956346346\n",
      "x0 int val: 343634\n",
      "x0 bin val: [0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "x0 int val: 6346346\n",
      "x0 bin val: [0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "y  int val: 6689980 and correct answer is 6689980\n",
      "y  bin val: [0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "Do you wish to perform a new calculation? (y/N)N\n"
     ]
    }
   ],
   "source": [
    "my_test_calc = RNNCalc(dtype, my_rnn)\n",
    "my_test_calc.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
